---
title: "Practical Machine Learning Course Project"
author: "Steven Johnson"
date: "Thursday, April 07, 2016"
output: html_document
---
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(RCurl)
library(caret)
```


## Introduction
In the Weight Lifting Exercises Dataset, six participants performed a set of 10 repetitions of the Unilateral Dumbbell Biceps Curl while wearing 3 body sensors using a sensor-enabled dumbell. The exercise was done in one of 5 different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Data from this experiment has been made avaliable as training and testing datasets.

The goals of this course project are the following: 

* Utilizing a machine learning approach, create a predictive model using the training data and predict the activity class in the 20 sample testing data.
* Use cross-validation and estimate the expected out of sample error of your approach.
* Create a report detailing data preprocessing, data partitioning, cross-validation, and model creation.

## Getting and Cleaning Data

Download the training data for this project.
```{r, DA1, cache=TRUE}
trainURL<-getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", ssl.verifypeer=0L, followlocation=1L)
training<-read.csv(text=trainURL)
```


Download the test data used for the Prediction Quiz portion of the project. 
```{r, DA2}
testURL<-getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", ssl.verifypeer=0L, followlocation=1L)
testing<-read.csv(text=testURL)
```

Remove training data columns with missing values, near zero variance, and extraneous columns.
```{r, DA3, cache=TRUE}
training<-training[,which(colSums(is.na(training))==0)]
training<-training[,-nearZeroVar(training)]
training<-training[,-c(1:6)]
```
This produces a training dataset with 19,622 observations on 52 different variables. 

Now that we have eliminated multiple columns from the training data, modify the testing data columns to match. Of course, the training classe column is an exception.
```{r, DA4}
testing<-testing[,names(training[,-c(53)])]
```

Exploratory examination of the source files reveals that columns with matching names in the training and testing data do not always have the same type. e.g. numeric versus integer. To be safe, these should be standardized. Set the training column types to those in the testing data.
```{r, DA5}
for(i in 1:dim(training[,-c(53)])[2]){
  class(training[,i])<-class(testing[,i])
}
```

## Partitioning Data

In order to estimate the out of sample error, the testing data was further partitioned into training(60%) and testing(40%) datasets.
```{r, DA6}
set.seed(1234)
myTrain<-createDataPartition(y=training$classe, p=0.60, list=FALSE)
mytraining<-training[myTrain,]
mytesting<-training[-myTrain,]
```

## Model Creation
Due to excellent performance as a general machine learning classifier, a random forest model was created using the training data.
```{r, MC1, eval=FALSE}
modFitRF2<-train(classe~., data=mytraining, method="rf", prox=TRUE)
```
```{r, MC2, echo=FALSE}
# Since the model creation step is so time consuming. The model has been saved and is reloaded.
load("modFitRF2.rDA")
```
Training data variable importance for this random forest model are as follows:
```{r, MC3, cache=TRUE}
varImpPlot(modFitRF2$finalModel, main="Relative importance of training variables\non Random Forest model", pch=19)
```
This plot shows the mean decrease in Gini coefficient, which is a measure of how much each variable contributes to node homogeneity, with the "roll belt" variable having the highest importance.

We can assess the performance of this model on the cross-validated testset created from the original training data. 



